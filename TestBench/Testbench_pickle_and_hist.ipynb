{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e8791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2a1ec",
   "metadata": {},
   "source": [
    "VEXT_STR_XXX.pkl --> ORDNER Vext_XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basisordner mit allen Vext_*.pkl Dateien\n",
    "base_dir = \"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/Vext_allTEMP_64grid_swing/\"\n",
    "\n",
    "# Regex-Muster: Vext_<STR>_<TEMP>.pkl\n",
    "pattern = re.compile(r\"^Vext_([A-Z]{3})_(\\d+)\\.pkl$\")\n",
    "\n",
    "# Alle Dateien im Basisordner durchgehen\n",
    "for filename in os.listdir(base_dir):\n",
    "    if not filename.endswith(\".pkl\"):\n",
    "        continue\n",
    "\n",
    "    match = pattern.match(filename)\n",
    "    if not match:\n",
    "        print(f\"‚ö†Ô∏è  √úbersprungen (kein passender Name): {filename}\")\n",
    "        continue\n",
    "\n",
    "    structure, temp = match.groups()\n",
    "    temp_folder = f\"Vext_{temp}\"  # z. B. \"Vext_400\"\n",
    "    temp_path = os.path.join(base_dir, temp_folder)\n",
    "\n",
    "    # Ordner erstellen, falls nicht vorhanden\n",
    "    os.makedirs(temp_path, exist_ok=True)\n",
    "\n",
    "    # Pfade f√ºr Verschieben\n",
    "    src = os.path.join(base_dir, filename)\n",
    "    dst = os.path.join(temp_path, filename)\n",
    "\n",
    "    # Datei verschieben\n",
    "    shutil.move(src, dst)\n",
    "    \n",
    "\n",
    "print(\"Alle Dateien wurden nach Temperatur-Unterordnern sortiert.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897de38",
   "metadata": {},
   "source": [
    "MIN/MAX GLOBAL PICKEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Basisordner mit den Unterordnern (z. B. Vext_400/, Vext_500/, ...)\n",
    "base_dir = \"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/Vext_allTEMP_32grid\"\n",
    "\n",
    "global_min = np.inf\n",
    "global_max = -np.inf\n",
    "count_files = 0\n",
    "\n",
    "# Alle Unterordner durchlaufen\n",
    "for folder in os.listdir(base_dir):\n",
    "    temp_path = os.path.join(base_dir, folder)\n",
    "    if not (os.path.isdir(temp_path) and folder.startswith(\"Vext_\")):\n",
    "        continue\n",
    "\n",
    "    #print(f\"\\nüìÇ Verarbeite {folder} ...\")\n",
    "\n",
    "    # Alle .pkl-Dateien in diesem Ordner\n",
    "    for filename in os.listdir(temp_path):\n",
    "        if not filename.endswith(\".pkl\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(temp_path, filename)\n",
    "\n",
    "        # Datei laden\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        # In NumPy-Array umwandeln\n",
    "        arr = np.asarray(data, dtype=np.float64).squeeze()\n",
    "\n",
    "        # NaN/Inf entfernen\n",
    "        arr = arr[np.isfinite(arr)]\n",
    "        if arr.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Lokales Min/Max\n",
    "        local_min = arr.min()\n",
    "        local_max = arr.max()\n",
    "\n",
    "        # Globales Min/Max aktualisieren\n",
    "        global_min = min(global_min, local_min)\n",
    "        global_max = max(global_max, local_max)\n",
    "        count_files += 1\n",
    "\n",
    "        #print(f\"  ‚úÖ {filename}: min={local_min:.3f}, max={local_max:.3f}\")\n",
    "\n",
    "# Gesamtergebnis\n",
    "if count_files > 0:\n",
    "    print(f\"\\n‚úÖ {count_files} Dateien verarbeitet\")\n",
    "    print(f\"üå°Ô∏è  Globales Minimum: {global_min:.3f}\")\n",
    "    print(f\"üå°Ô∏è  Globales Maximum: {global_max:.3f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Keine .pkl-Dateien gefunden.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98062edd",
   "metadata": {},
   "source": [
    "VISUALISIERUNG VEXT RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d83da3-930a-4404-a155-bddf824a5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/Vext_allTEMP/Vext_400/Vext_MWW_400.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "cutoff = 10.1\n",
    "mask = data < cutoff\n",
    "data = jnp.array(data)\n",
    "#data = np.exp(-data)\n",
    "data_mask = data[mask]\n",
    "print(data.shape)\n",
    "print(data_mask.shape)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(data_mask, bins=100, color=\"green\", edgecolor=\"black\")\n",
    "plt.xlabel(r\"$\\beta V^{\\mathrm{ext}}$\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.ylim(0, 100000)\n",
    "plt.title(f\"Histogram of external potential\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\n",
    "#    \"beta_Vext_histogram_example_MWW2.png\",\n",
    "#    dpi=300,\n",
    "#    bbox_inches=\"tight\"\n",
    "#)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d0f62",
   "metadata": {},
   "source": [
    "VEXT HIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ba397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "VEXT_MAX = 10.1       # cutoff oben\n",
    "VEXT_MIN = -15     # cutoff unten global \"-14.744\"\n",
    "N_BINS   = 100\n",
    "\n",
    "base_dir = \"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/Vext_allTEMP\"\n",
    "pattern  = re.compile(r\"Vext_([A-Z]{3})_(\\d+)\\.pkl\")\n",
    "\n",
    "all_dfs = []\n",
    "counter = 0\n",
    "# temp ordner iterieren\n",
    "for temp_folder in os.listdir(base_dir):\n",
    "    temp_path = os.path.join(base_dir, temp_folder)\n",
    "    if not (os.path.isdir(temp_path) and temp_folder.startswith(\"Vext_\")):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nBearbeite Temperatur-Ordner: {temp_folder}\")\n",
    "    rows = []\n",
    "\n",
    "    # alle pickle daten\n",
    "    for filename in os.listdir(temp_path):\n",
    "        if not filename.endswith(\".pkl\"):\n",
    "            continue\n",
    "\n",
    "        m = pattern.match(filename)\n",
    "        if not m:\n",
    "            print(f\"√úbersprungen (kein g√ºltiger Name): {filename}\")\n",
    "            continue\n",
    "\n",
    "        struct_name, temp = m.groups()\n",
    "        file_path = os.path.join(temp_path, filename)\n",
    "\n",
    "        # Entpickeln\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        arr = np.asarray(data, dtype=np.float64).squeeze()\n",
    "        arr = arr[np.isfinite(arr)]  # NaN/Inf entfernen\n",
    "\n",
    "        if arr.size != 32**3:\n",
    "            counter += 1\n",
    "        print(counter)\n",
    "\n",
    "        # Mask und exp(-)\n",
    "        if arr.size == 0:\n",
    "            hist = np.zeros(N_BINS, dtype=int)\n",
    "            edges = np.linspace(0, 1, N_BINS + 1)\n",
    "        else:\n",
    "            #arr = np.clip(arr, VEXT_MIN, VEXT_MAX)\n",
    "            #arr_exp = np.exp(-arr)\n",
    "            hist, edges = np.histogram(arr, bins=N_BINS, range=(VEXT_MIN, VEXT_MAX)) # automatisch √§quistante bins\n",
    "\n",
    "        # struktur\n",
    "        entry = {\"structure\": struct_name, \"temperature\": int(temp)}\n",
    "        entry.update({f\"bin_{i}\": int(v) for i, v in enumerate(hist)})\n",
    "        entry[\"x_min\"] = float(edges[-1])\n",
    "        entry[\"x_max\"] = float(edges[0])\n",
    "        rows.append(entry)\n",
    "\n",
    "    # -\n",
    "    if rows:\n",
    "        df_temp = pd.DataFrame(rows)\n",
    "        all_dfs.append(df_temp)\n",
    "        print(f\"{len(rows)} Strukturen verarbeitet\")\n",
    "\n",
    "# df_all zusammenf√ºhren\n",
    "df_all = pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()\n",
    "print(f\"\\n Gesamt-DataFrame mit {len(df_all)} Zeilen erstellt\")\n",
    "\n",
    "# csv\n",
    "out_name = f\"Vext_allTEMP_noexp_rangelinBin_cut{VEXT_MAX}_{VEXT_MIN}_{N_BINS}Bins.csv\"\n",
    "out_path = os.path.join(base_dir, out_name)\n",
    "df_all.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Datei gespeichert unter:\\n{out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51813c65",
   "metadata": {},
   "source": [
    "ANALYSE HIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14442115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/Vext_allTEMP_32grid/Vext_allTEMP_noexp_rangelinBin_cut10.1_-15_100Bins_32grid.csv\")\n",
    "\n",
    "#min_val = df[\"bin_2\"].min()\n",
    "#max_val = df[\"bin_2\"].max()\n",
    "\n",
    "structure = \"BCT\"\n",
    "\n",
    "# Zeilen dieser Struktur ausw√§hlen (falls mehrere Temperaturen vorhanden sind)\n",
    "#df_sel = df[df[\"structure\"] == structure]\n",
    "\n",
    "# Wenn du nur eine bestimmte Temperatur willst:\n",
    "df_sel = df[(df[\"structure_name\"] == structure) & (df[\"temperature_kelvin\"] == 300)]\n",
    "\n",
    "# Sicherstellen, dass √ºberhaupt Daten da sind\n",
    "if df_sel.empty:\n",
    "    raise ValueError(f\"Keine Daten f√ºr Struktur {structure} gefunden!\")\n",
    "\n",
    "# Wir nehmen hier die erste Zeile (z. B. Temperatur 400)\n",
    "row = df_sel.iloc[0]\n",
    "\n",
    "# Histogrammdaten extrahieren\n",
    "bin_cols = [c for c in df.columns if c.startswith(\"bin_\")]\n",
    "y = row[bin_cols].values\n",
    "\n",
    "# x-Achse rekonstruieren (gleichm√§√üig zwischen x_min und x_max)\n",
    "x_max = row[\"x_min\"]\n",
    "x_min = row[\"x_max\"]\n",
    "x_edges = np.linspace(x_min, x_max, len(bin_cols) + 1)\n",
    "x_centers = 0.5 * (x_edges[:-1] + x_edges[1:])  # Mitten der Bins\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_centers, y, marker=\"o\", lw=1.5)\n",
    "#plt.xlim(-15,9)\n",
    "#plt.ylim(0, 4000)\n",
    "plt.title(f\"Histogramm f√ºr Struktur {structure} (Temp {int(row['temperature'])} K)\")\n",
    "plt.xlabel(\"Vext (x)\")\n",
    "plt.ylabel(\"H√§ufigkeit / Bin\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5362fc54",
   "metadata": {},
   "source": [
    "DFT - CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f864c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Entfernen\n",
    "\n",
    "dft_data = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/2025_10_5_DB_100Bins_DOTO.csv\")\n",
    "\n",
    "dft_data = dft_data.loc[:, ~dft_data.columns.str.isdigit()]\n",
    "\n",
    "output_path = \"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/DFT_Data_clean_06_10.csv\"\n",
    "dft_data.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klammern entfernen\n",
    "\n",
    "df = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/DFT_Data_clean_06_10.csv\")\n",
    "\n",
    "df[\"density_bulk\"] = pd.to_numeric(\n",
    "    df[\"density_bulk\"].astype(str)\n",
    "      .str.replace(r\"^\\s*\\[\\s*\", \"\", regex=True)  # f√ºhrende '[' entfernen\n",
    "      .str.replace(r\"\\s*\\]\\s*$\", \"\", regex=True)  # schlie√üende ']' entfernen\n",
    "      .str.strip(),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "print(df[\"density_bulk\"].head(), df[\"density_bulk\"].dtype)  # sollte float64 sein\n",
    "\n",
    "\n",
    "#df[\"density_bulk\"].values\n",
    "\n",
    "df.to_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/DFT_Data_clean_06_10.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
