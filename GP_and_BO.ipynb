{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7de269-6e81-4829-85d5-52736f117b8d",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028c67a-781a-43a1-a107-e9f5c0529e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import gpytorch\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62980962-b8b1-4c57-b633-0aee60654a85",
   "metadata": {},
   "source": [
    "Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262a9b9-c46b-4a5b-a094-50653c985467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bin_column(col) -> bool:\n",
    "    \"\"\"\n",
    "    BIN recognition\n",
    "    \"\"\"\n",
    "    if isinstance(col, (int, np.integer)):\n",
    "        return True\n",
    "\n",
    "    s = str(col)\n",
    "    if s.isdigit():                 # '0', '1', ...\n",
    "        return True\n",
    "    if re.fullmatch(r\"bin_\\d+\", s): # 'bin_0', 'bin_1', ...\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5da10-fa24-469b-bb31-b0890c63fef9",
   "metadata": {},
   "source": [
    "GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c63279-3f64-4cb8-ac0d-8f6e77c136fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def train_gp(xt_train, yt_train, training_iterations=100):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(xt_train, yt_train, likelihood)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.2)\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xt_train)\n",
    "        loss = -mll(output, yt_train)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model.eval(), likelihood.eval(), losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a3aeb6-2163-4da8-9c30-0a43c395839c",
   "metadata": {},
   "source": [
    "Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4910e6-a175-4a9c-b6bb-b2ff1ee11d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_data = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/dft_data_temp_pressure_swingswingswing.csv\")\n",
    "Vext_data = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/Vext_allTEMP_hist_no_pressure_no_chem_20b_swing.csv\")\n",
    "\n",
    "data = pd.merge(dft_data, Vext_data, 'inner', on=[\"structure_name\", \"temperature_kelvin\"])\n",
    "feature_columns = [col for col in data.columns if is_bin_column(col)]\n",
    "\n",
    "data = data[data.beladung_mol_per_kg > 0]\n",
    "data = data[(data.temperature_kelvin == 298) & (data.pressure_bar == 0.1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe65453-c385-4e64-abfb-1466ce015130",
   "metadata": {},
   "source": [
    "Feature & Label customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e775c5-84d3-473d-b52a-fc0191339d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"beladung_pro_vol\"] = (\n",
    "    data[\"beladung_atoms\"]\n",
    "    #.div(data[\"density_bulk\"], axis=0)\n",
    "    .div(data[\"volume_kubAng\"], axis=0)\n",
    ")\n",
    "\n",
    "data[feature_columns] = (\n",
    "    data[feature_columns]\n",
    "    .multiply(data[\"grid.dv\"], axis=0)\n",
    "    .div(data[\"volume_kubAng\"], axis=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96087ca9-344f-4574-b4b2-a8d0914b87b5",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25029cd6-9bfe-4d0d-913a-ad918eedf0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_feature = True\n",
    "normalize_labels = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da080a3-b143-4185-9173-1047c121c720",
   "metadata": {},
   "source": [
    "Fold & Training & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8003d04-b3ec-4ff3-8b8b-a2c5f80a428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "label = \"beladung_pro_vol\"\n",
    "X = data[feature_columns].values \n",
    "y = data[label].values \n",
    "\n",
    "ids = data.index.values\n",
    "\n",
    "split_info = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X), start=1):\n",
    "    x_train = torch.tensor(X[train_idx], dtype=torch.float64)\n",
    "    y_train = torch.tensor(y[train_idx], dtype=torch.float64)\n",
    "    x_test = torch.tensor(X[test_idx], dtype=torch.float64)\n",
    "    y_test = torch.tensor(y[test_idx], dtype=torch.float64)\n",
    "\n",
    "    train_ids = ids[train_idx]\n",
    "    test_ids = ids[test_idx]\n",
    "\n",
    "    test_df = data.iloc[test_idx].copy()\n",
    "    test_df[\"fold\"] = fold\n",
    "\n",
    "    if normalize_feature:\n",
    "        feature_transformer = MinMaxScaler()\n",
    "        feature_transformer.fit(x_train)\n",
    "        xt_train = torch.tensor(feature_transformer.transform(x_train), dtype=torch.float64)\n",
    "        xt_test = torch.tensor(feature_transformer.transform(x_test), dtype=torch.float64) #*2\n",
    "    else:\n",
    "        xt_train = x_train\n",
    "        xt_test = x_test\n",
    "\n",
    "    if normalize_labels:\n",
    "        label_transformer = MinMaxScaler()  # oder StandardScaler()\n",
    "        label_transformer.fit(y_train.unsqueeze(1))\n",
    "        yt_train = torch.tensor(label_transformer.transform(y_train.unsqueeze(1)).flatten(), dtype=torch.float64)\n",
    "        yt_test = torch.tensor(label_transformer.transform(y_test.unsqueeze(1)).flatten(), dtype=torch.float64)\n",
    "    else:\n",
    "        yt_train = y_train\n",
    "        yt_test = y_test\n",
    "\n",
    "    # Training\n",
    "    model, likelihood, losses = train_gp(xt_train, yt_train, training_iterations=200)\n",
    "\n",
    "    # Prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = model(xt_test)\n",
    "        inverse_transformed_prediction = label_transformer.inverse_transform(\n",
    "            prediction.mean.unsqueeze(1)\n",
    "        ).squeeze()\n",
    "        inverse_transformed_prediction = np.where(\n",
    "            inverse_transformed_prediction > 0, inverse_transformed_prediction, 0\n",
    "        )\n",
    "\n",
    "    test_df[f\"{label}_pred\"] = inverse_transformed_prediction\n",
    "    test_df[\"abs_rel_deviation\"] = np.abs(\n",
    "        (test_df[label] - test_df[f\"{label}_pred\"]) / test_df[label] * 100\n",
    "    )\n",
    "\n",
    "    split_info.append(test_df)\n",
    "\n",
    "results = pd.concat(split_info, ignore_index=True)\n",
    "r2 = r2_score(results[label], results[f\"{label}_pred\"])\n",
    "mae = mean_absolute_error(results[label], results[f\"{label}_pred\"])\n",
    "median_ape = results[\"abs_rel_deviation\"].median()\n",
    "\n",
    "results[\"R2\"] = r2\n",
    "results[\"MAE\"] = mae\n",
    "results[\"Median_APE_percent\"] = median_ape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09176979-8348-4f99-a8c0-4f6dfa5b1916",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab80a2-3101-4bcf-974c-0c844c0d61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R²                        : {r2_score(results[label], results[f'{label}_pred']):.4f}\")\n",
    "print(f\"MAE                       : {mean_absolute_error(results[label], results[f'{label}_pred']):.4f}\")\n",
    "print(f\"Median APE                : {results['abs_rel_deviation'].median():.2f}%\")\n",
    "print(f\"Mean APE                  : {results['abs_rel_deviation'].mean():.2f}%\")\n",
    "print(f\"Final Loss                : {losses[-1]:.4f}\")\n",
    "\n",
    "count = (results['abs_rel_deviation'] > 20).sum()\n",
    "print(f\"Abs rel dev > 20%         : {count} out of {len(results)}\")\n",
    "print(f\"Max abs rel dev           : {results['abs_rel_deviation'].max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6f353-d6dd-4da7-9ca4-4ac792d9ec38",
   "metadata": {},
   "source": [
    "Result by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e8e3c-c04e-4d46-9e32-c20520111bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, group in results.groupby(\"fold\"):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    print(f\"R²           : {r2_score(group[label], group[f'{label}_pred']):.4f}\")\n",
    "    print(f\"Median APE   : {group['abs_rel_deviation'].median():.2f}%\")\n",
    "    print(f\"Mean APE     : {group['abs_rel_deviation'].mean():.2f}%\")\n",
    "    print(f\"Max ARD      : {group['abs_rel_deviation'].max():.2f}%\")\n",
    "    print(f\"Final Loss   : {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb2f37-dfa3-41c4-9e65-537372bb626c",
   "metadata": {},
   "source": [
    "Acquisition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d936c-8034-4a29-8d33-875cff6e5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_expected_improvement(mean, var, best_f, xi=0.0):\n",
    "    std = torch.sqrt(var)\n",
    "    std_safe = torch.clamp(std, min=1e-9)\n",
    "    z = (mean - best_f - xi) / std_safe\n",
    "\n",
    "    normal = Normal(torch.zeros_like(z), torch.ones_like(z))\n",
    "    cdf = normal.cdf(z)\n",
    "    pdf = torch.exp(normal.log_prob(z))\n",
    "\n",
    "    ei = std * (z * cdf + pdf)\n",
    "    ei_safe = torch.clamp(ei, min=1e-10)\n",
    "    return torch.log(ei_safe)\n",
    "\n",
    "def ucb(mean, var, beta=2.0):\n",
    "    std = torch.sqrt(var)\n",
    "    return mean + beta * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf706351-49ab-435f-ae46-4090e24588f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_indices_kmeans(df, feature_columns, n_initial, random_state=0):\n",
    "    \"\"\"Pick diverse initial points via KMeans (closest point to each centroid).\"\"\"\n",
    "    X = df[feature_columns].values\n",
    "    if len(df) <= n_initial:\n",
    "        return df.index\n",
    "\n",
    "    km = KMeans(n_clusters=n_initial, n_init=1, random_state=random_state)\n",
    "    labels = km.fit_predict(X)\n",
    "    centers = km.cluster_centers_\n",
    "\n",
    "    picked = []\n",
    "    for k in range(n_initial):\n",
    "        members = np.where(labels == k)[0]\n",
    "        if len(members) == 0:\n",
    "            continue\n",
    "\n",
    "        d = np.linalg.norm(X[members] - centers[k], axis=1)\n",
    "        picked.append(df.index[members[np.argmin(d)]])\n",
    "\n",
    "    if len(picked) < n_initial:\n",
    "        rest = df.index.difference(picked)\n",
    "        extra = np.random.default_rng(random_state).choice(rest, size=(n_initial - len(picked)), replace=False)\n",
    "        picked.extend(list(extra))\n",
    "    return pd.Index(picked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5468e4-998f-48a2-abe5-cf4e367961e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = data.copy()\n",
    "n_candidates = int(len(candidates))\n",
    "\n",
    "max_iter = 100\n",
    "patience = 10\n",
    "\n",
    "init = \"kmeans\"\n",
    "\n",
    "acq = \"ucb\"\n",
    "\n",
    "xi_mode = \"anneal\"   \n",
    "xi0 = 0.05           \n",
    "xi_min = 0.005      \n",
    "\n",
    "beta_mode = \"anneal\"  \n",
    "beta0 = 3.0\n",
    "beta_min = 1.0\n",
    "\n",
    "n_initial = max(3, min(10, n_candidates - 1))  \n",
    "\n",
    "feature_transformer = MinMaxScaler()\n",
    "label_transformer = MinMaxScaler()\n",
    "\n",
    "feature_transformer.fit(candidates[feature_columns].values)\n",
    "label_transformer.fit(candidates[[label]].values)\n",
    "\n",
    "if init == \"kmeans\":\n",
    "    initial_indices = initial_indices_kmeans(candidates, feature_columns, n_initial, random_state=0)\n",
    "else:\n",
    "    initial_indices = candidates.sample(n=n_initial, replace=False, random_state=0).index\n",
    "\n",
    "print(\"Initial selections:\")\n",
    "for idx in initial_indices:\n",
    "    print(f\"  Index={idx}, Structure={candidates.loc[idx].structure_name}, {label}={candidates.loc[idx][label]:.2e}\")\n",
    "\n",
    "selected = candidates.loc[initial_indices].copy()\n",
    "candidates = candidates.drop(initial_indices).copy()\n",
    "\n",
    "best = [float(selected[label].max())]\n",
    "\n",
    "for i in range(max_iter):\n",
    "\n",
    "    if len(best) >= patience and len(np.unique(np.round(best[-patience:], 12))) == 1:\n",
    "        print(f\"Early stopping at iteration {i} (no improvement in last {patience}).\")\n",
    "        break\n",
    "\n",
    "    train_x = torch.tensor(\n",
    "        feature_transformer.transform(selected[feature_columns].values),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    train_y = torch.tensor(\n",
    "        label_transformer.transform(selected[[label]].values),\n",
    "        dtype=torch.float32\n",
    "    ).flatten()\n",
    "\n",
    "    test_x = torch.tensor(\n",
    "        feature_transformer.transform(candidates[feature_columns].values),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    model, likelihood, _ = train_gp(train_x, train_y, 250)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(test_x)\n",
    "        mean, var = pred.mean, pred.variance\n",
    "\n",
    "    best_f = train_y.max()\n",
    "\n",
    "    if acq == \"ei\":\n",
    "        if xi_mode == \"anneal\":\n",
    "            xi = max(xi_min, xi0 * (0.95 ** i))\n",
    "        else:\n",
    "            xi = xi0\n",
    "\n",
    "        score = log_expected_improvement(mean, var, best_f, xi=xi)\n",
    "        pick = torch.argmax(score).item()\n",
    "\n",
    "    elif acq == \"ucb\":\n",
    "        if beta_mode == \"anneal\":\n",
    "            beta = max(beta_min, beta0 * (0.97 ** i))\n",
    "        else:\n",
    "            beta = beta0\n",
    "\n",
    "        score = ucb(mean, var, beta=beta)\n",
    "        pick = torch.argmax(score).item()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"acq must be 'ei' or 'ucb'\")\n",
    "\n",
    "    current_best = float(selected[label].max())\n",
    "    picked_row = candidates.iloc[pick]\n",
    "    picked_true = float(picked_row[label])\n",
    "    picked_name = picked_row[\"structure_name\"]\n",
    "\n",
    "    print(\n",
    "        f\"Iter {i:03d} | best={current_best:.3e} | pick={picked_name} | true={picked_true:.3e} | \"\n",
    "        f\"acq={acq} \" +\n",
    "        (f\"(xi={xi:.3g})\" if acq == \"ei\" else f\"(beta={beta:.3g})\")\n",
    "    )\n",
    "\n",
    "    selected = pd.concat([selected, candidates.iloc[[pick]]])\n",
    "    candidates = candidates.drop(candidates.index[pick])\n",
    "\n",
    "    best.append(float(selected[label].max()))\n",
    "\n",
    "print(f\"Best value after {len(best)-1} iterations: {best[-1]:.6g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9438d-ef7c-4c0c-9542-794fce0f09f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32cb1c-f43a-4773-98a1-3567c6a463b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
