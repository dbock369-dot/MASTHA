{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5560e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn.metrics import r2_score\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import gpytorch\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52f9fd",
   "metadata": {},
   "source": [
    "UTILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp_results(candidates, mean_np, std_np, ei_np, pi_np, iteration, label=\"target_value\"):\n",
    "    x = np.arange(len(candidates))  # Struktur-Index\n",
    "    names = candidates[\"structure_name\"].values\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    axs[0].plot(x, mean_np, color=\"C0\", label=\"Predicted Mean\")\n",
    "    axs[0].fill_between(x, mean_np - std_np, mean_np + std_np, color=\"C0\", alpha=0.3, label=\"Uncertainty (±1σ)\")\n",
    "    axs[0].set_ylabel(\"Predicted Mean\")\n",
    "    axs[0].set_title(f\"Iteration {iteration}: GP Prediction (mean ± std)\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(alpha=0.3)\n",
    "\n",
    "    axs[1].plot(x, ei_np, color=\"C1\")\n",
    "    axs[1].set_ylabel(\"Expected Improvement\")\n",
    "    axs[1].set_title(\"Expected Improvement over Candidates\")\n",
    "    axs[1].grid(alpha=0.3)\n",
    "\n",
    "    axs[2].plot(x, pi_np, color=\"C2\")\n",
    "    axs[2].set_ylabel(\"Probability of Improvement\")\n",
    "    axs[2].set_xlabel(\"Candidate Structure Index\")\n",
    "    axs[2].set_title(\"Probability of Improvement\")\n",
    "    axs[2].grid(alpha=0.3)\n",
    "\n",
    "    # Optional: Struktur-Namen als xticks (nur alle paar, sonst zu viele)\n",
    "    if len(names) <= 30:\n",
    "        axs[2].set_xticks(x)\n",
    "        axs[2].set_xticklabels(names, rotation=90)\n",
    "    else:\n",
    "        step = max(1, len(names)//30)\n",
    "        axs[2].set_xticks(x[::step])\n",
    "        axs[2].set_xticklabels(names[::step], rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bin_column(col) -> bool:\n",
    "    # numerische Spaltennamen erlauben\n",
    "    if isinstance(col, (int, np.integer)):\n",
    "        return True\n",
    "\n",
    "    s = str(col)\n",
    "\n",
    "    # rein numerischer Spaltenname: '0', '1', ...\n",
    "    if s.isdigit():\n",
    "        return True\n",
    "\n",
    "    # bin_X oder bin_X_high / bin_X_low\n",
    "    if re.fullmatch(r\"bin_\\d+(_high|_low)?\", s):\n",
    "        return True\n",
    "    if re.fullmatch(r\"bin_\\d+\", s): # 'bin_0', 'bin_1', ...\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e053c4b",
   "metadata": {},
   "source": [
    "MODELL GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def train_gp(xt_train, yt_train, training_iterations=100):\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(xt_train, yt_train, likelihood)\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.2)\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(xt_train)\n",
    "        loss = -mll(output, yt_train)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model.eval(), likelihood.eval(), losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3c573-aad3-44bf-9e53-06ac244f635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datenfilternundfertigmachenfür(data, temp1, temp2, pres1, pres2):\n",
    "    # wc(p, T) -> high\n",
    "    data_high = data[(data.temperature_kelvin == temp1) & (data.pressure_bar == pres1)]\n",
    "    data_high = data_high.drop_duplicates(subset=[\"structure_name\", \"temperature_kelvin\", \"pressure_bar\"])\n",
    "    feature_columns_high = [col for col in data_high.columns if is_bin_column(col)]\n",
    "    \n",
    "    # wc(p, T) -> low\n",
    "    data_low = data[(data.temperature_kelvin == temp2) & (data.pressure_bar == pres2)]\n",
    "    data_low = data_low.drop_duplicates(subset=[\"structure_name\", \"temperature_kelvin\", \"pressure_bar\"])\n",
    "    feature_columns_low = [col for col in data_low.columns if is_bin_column(col)]\n",
    "\n",
    "    add_features = True\n",
    "    \n",
    "    data_high[\"beladung_pro_vol\"] = (\n",
    "        data_high[\"beladung_atoms\"]\n",
    "        #.div(data_high[\"density_bulk\"], axis=0)\n",
    "        .div(data_high[\"volume_kubAng\"], axis=0)\n",
    "    )\n",
    "    \n",
    "    data_low[\"beladung_pro_vol\"] = (\n",
    "        data_low[\"beladung_atoms\"]\n",
    "        #.div(data_low[\"density_bulk\"], axis=0)\n",
    "        .div(data_low[\"volume_kubAng\"], axis=0)\n",
    "    )\n",
    "    \n",
    "    data_high[feature_columns_high] = (\n",
    "        data_high[feature_columns_high]\n",
    "        .multiply(data_high[\"grid.dv\"], axis=0)\n",
    "        .div(data_high[\"volume_kubAng\"], axis=0)\n",
    "    )\n",
    "    \n",
    "    data_low[feature_columns_low] = (\n",
    "        data_low[feature_columns_low]\n",
    "        .multiply(data_low[\"grid.dv\"], axis=0)\n",
    "        .div(data_low[\"volume_kubAng\"], axis=0)\n",
    "    )\n",
    "    \n",
    "    additional_features12 = [\"delta_p\", \"delta_T\"]\n",
    "    additional_features12 = [\"chem_potential_bulk_high\", \"chem_potential_bulk_low\", \"pressure_bar_high\", \"pressure_bar_low\", \"temperature_kelvin_high\", \"temperature_kelvin_low\"]\n",
    "    additional_features = [\"pressure_bar_high\", \"pressure_bar_low\", \"temperature_kelvin_high\", \"temperature_kelvin_low\"]\n",
    "\n",
    "    merged = pd.merge(\n",
    "        #data_high[[\"structure_name\", \"beladung_pro_vol\"]],\n",
    "        #data_low[[\"structure_name\", \"beladung_pro_vol\"]],\n",
    "        data_high,#[cols],\n",
    "        data_low,#[cols],\n",
    "        on=\"structure_name\",\n",
    "        suffixes=(\"_high\", \"_low\")\n",
    "    )\n",
    "    \n",
    "    # wc aus den beiden Zuständen high/low\n",
    "    merged[\"working_capacity\"] = (merged[\"beladung_pro_vol_high\"] - merged[\"beladung_pro_vol_low\"]).abs()\n",
    "    merged[\"delta_T\"] = (merged[\"temperature_kelvin_high\"] - merged[\"temperature_kelvin_low\"]).abs()\n",
    "    merged[\"delta_p\"] = (merged[\"pressure_bar_high\"] - merged[\"pressure_bar_low\"]).abs()\n",
    "    feature_columns = [col for col in merged.columns if is_bin_column(col)]\n",
    "    \n",
    "    if add_features:\n",
    "        feature_columns += additional_features\n",
    "    \n",
    "    merged[\"working_capacity\"] = pd.to_numeric(merged[\"working_capacity\"], errors=\"coerce\")\n",
    "    \n",
    "    return merged, feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4943dc",
   "metadata": {},
   "source": [
    "NORMALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_feature = True\n",
    "normalize_labels = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438ab1b3",
   "metadata": {},
   "source": [
    "FOLD - TRAINING - PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06b91dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPGPGP(merged, feature_columns):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    label = \"working_capacity\"\n",
    "    #X = data[feature_columns].values \n",
    "    X = merged[feature_columns].values\n",
    "    #y = data[label].values \n",
    "    y = merged[label].values \n",
    "    #print(merged.head())\n",
    "    ids = data.index.values\n",
    "    \n",
    "    split_info = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), start=1):\n",
    "        x_train = torch.tensor(X[train_idx], dtype=torch.float64)\n",
    "        y_train = torch.tensor(y[train_idx], dtype=torch.float64)\n",
    "        x_test = torch.tensor(X[test_idx], dtype=torch.float64)\n",
    "        y_test = torch.tensor(y[test_idx], dtype=torch.float64)\n",
    "    \n",
    "        train_ids = ids[train_idx]\n",
    "        test_ids = ids[test_idx]\n",
    "    \n",
    "        #test_df = data.iloc[test_idx].copy()\n",
    "        test_df = merged.iloc[test_idx].copy()\n",
    "        test_df[\"fold\"] = fold\n",
    "    \n",
    "        if normalize_feature:\n",
    "            feature_transformer = MinMaxScaler()\n",
    "            feature_transformer.fit(x_train)\n",
    "            xt_train = torch.tensor(feature_transformer.transform(x_train), dtype=torch.float64)\n",
    "            xt_test = torch.tensor(feature_transformer.transform(x_test), dtype=torch.float64) #*2\n",
    "        else:\n",
    "            xt_train = x_train\n",
    "            xt_test = x_test\n",
    "    \n",
    "        # Label-Normalisierung\n",
    "        if normalize_labels:\n",
    "            label_transformer = MinMaxScaler()  # oder StandardScaler()\n",
    "            label_transformer.fit(y_train.unsqueeze(1))\n",
    "            yt_train = torch.tensor(label_transformer.transform(y_train.unsqueeze(1)).flatten(), dtype=torch.float64)\n",
    "            yt_test = torch.tensor(label_transformer.transform(y_test.unsqueeze(1)).flatten(), dtype=torch.float64)\n",
    "        else:\n",
    "            yt_train = y_train\n",
    "            yt_test = y_test\n",
    "    \n",
    "        # Training\n",
    "        model, likelihood, losses = train_gp(xt_train, yt_train, training_iterations=200)\n",
    "    \n",
    "        # Prediction\n",
    "        with torch.no_grad():\n",
    "            prediction = model(xt_test)\n",
    "            inverse_transformed_prediction = label_transformer.inverse_transform(\n",
    "                prediction.mean.unsqueeze(1)\n",
    "            ).squeeze()\n",
    "            inverse_transformed_prediction = np.where(\n",
    "                inverse_transformed_prediction > 0, inverse_transformed_prediction, 0\n",
    "            )\n",
    "    \n",
    "        # Ergebnisse\n",
    "        test_df[f\"{label}_pred\"] = inverse_transformed_prediction\n",
    "        test_df[\"abs_rel_deviation\"] = np.abs(\n",
    "            (test_df[label] - test_df[f\"{label}_pred\"]) / test_df[label] * 100\n",
    "        )\n",
    "    \n",
    "        split_info.append(test_df)\n",
    "    \n",
    "    results = pd.concat(split_info, ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4098c8",
   "metadata": {},
   "source": [
    "ALLE DATEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmirmeinenscheiss(results, label=\"working_capacity\"):\n",
    "    print(f\"R²                        : {r2_score(results[label], results[f'{label}_pred']):.4f}\")\n",
    "    print(f\"Median APE                : {results['abs_rel_deviation'].median():.2f}%\")\n",
    "    print(f\"Mean APE                  : {results['abs_rel_deviation'].mean():.2f}%\")\n",
    "    #print(f\"Final Loss                : {losses[-1]:.4f}\")\n",
    "    \n",
    "    count = (results['abs_rel_deviation'] > 20).sum()\n",
    "    print(f\"Abs rel dev > 20%         : {count} out of {len(results)}\")\n",
    "    print(f\"Max abs rel dev           : {results['abs_rel_deviation'].max():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21ed49",
   "metadata": {},
   "source": [
    "BAYESIAN OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "def af_log_expIm(mean, var, best_f, xi=0.01):\n",
    "    \"\"\"Logarithmic Expected Improvement acquisition function.\"\"\"\n",
    "\n",
    "    std = torch.sqrt(var)\n",
    "    std_safe = torch.clamp(std, min=1e-9)  # Avoid division by zero\n",
    "    z = (mean - best_f - xi) / std_safe\n",
    "    normal = Normal(torch.zeros_like(z), torch.ones_like(z))\n",
    "    cdf = normal.cdf(z)\n",
    "    pdf = torch.exp(normal.log_prob(z))\n",
    "\n",
    "    ei = std * (z * cdf + pdf)\n",
    "\n",
    "    ei_safe = torch.clamp(ei, min=1e-9)  # Avoid log(0)\n",
    "    log_ei = torch.log(ei_safe)\n",
    "    return log_ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17231322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bimbamBO():\n",
    "    candidates = merged.copy() # zunächst gefilteret, später alle Daten\n",
    "    \n",
    "    patience = 10\n",
    "    \n",
    "    n_initial = 1 # Anzahl der initialen Trainingspunkte\n",
    "    initial_indices = candidates.nsmallest(n_initial, label).index # hier geht auch random\n",
    "    \n",
    "    #print(f\"Initial training points:\")\n",
    "    for idx in initial_indices:\n",
    "        #print(f\"  Index {idx}, Structure {candidates.loc[idx, 'structure_name']}, {label}: {candidates.loc[idx, label]:.4f}\")\n",
    "    \n",
    "    # Transfer from candidates to selection\n",
    "    selected = candidates.loc[initial_indices]\n",
    "    candidates = candidates.drop(initial_indices)\n",
    "    best = [selected[label].max()]\n",
    "    \n",
    "    for i in range(100):\n",
    "        if len(best) >= patience:\n",
    "            if len(np.unique(best[-patience:])) == 1:\n",
    "                #print(f\"Early stopping at iteration {i} due to no improvement in the last {patience} iterations.\")\n",
    "                break\n",
    "        \n",
    "        feature_transoformer = MinMaxScaler()\n",
    "        label_transformer = MinMaxScaler()\n",
    "    \n",
    "        train_x = torch.tensor(feature_transoformer.fit_transform(selected[feature_columns].values))\n",
    "        train_y = torch.tensor(label_transformer.fit_transform(selected[[label]].values)).flatten()\n",
    "    \n",
    "        test_x = torch.tensor(feature_transoformer.transform(candidates[feature_columns].values))\n",
    "    \n",
    "        model, likelihood, _ = train_gp(train_x, train_y, 250)\n",
    "        with torch.no_grad():\n",
    "            prediction = model(test_x)\n",
    "            mean, var = prediction.mean, prediction.variance\n",
    "        \n",
    "        best_f = train_y.max()\n",
    "    \n",
    "        log_ei = af_log_expIm(mean, var, best_f, 0.01 * best_f)\n",
    "    \n",
    "        # Select the candidate with the highest acquisition value\n",
    "        index = torch.argmax(log_ei).item()\n",
    "        best.append(selected[label].max())\n",
    "        #print(f\"Iteration: {i}, Current Best: {selected[label].max():.2e}\")\n",
    "        selected = pd.concat([selected, candidates.iloc[[index]]])\n",
    "        canidates = candidates.drop(candidates.index[index])\n",
    "    \n",
    "    #print(f\"Best Value after {len(best)} iterations: {best[-1]}\")\n",
    "    \n",
    "    mean_np = mean.detach().cpu().numpy().flatten()\n",
    "    var_np = var.detach().cpu().numpy().flatten()\n",
    "    std_np = np.sqrt(var_np)\n",
    "    ei_np = torch.exp(log_ei).detach().cpu().numpy().flatten()\n",
    "    \n",
    "    # --- Probability of Improvement ---\n",
    "    best_f = train_y.max().item()\n",
    "    z = (mean_np - best_f) / std_np\n",
    "    pi_np = norm.cdf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259fd06d-0a9f-48df-a09e-20cfc6a7001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempunddruckunique(data):\n",
    "    temperatures = sorted(data['temperature_kelvin'].unique())\n",
    "    pressures = sorted(data['pressure_bar'].unique())\n",
    "    combinations = list(\n",
    "        data[['temperature_kelvin', 'pressure_bar']]\n",
    "        .drop_duplicates()\n",
    "        .itertuples(index=False, name=None)\n",
    "    )\n",
    "    return temperatures, pressures, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a513d1-82c2-4a1a-acea-df4aab95171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft Daten - beladungen, grid etc\n",
    "dft_data1 = pd.read_csv('/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/DFT_Data_clean_06_10.csv')\n",
    "dft_data2 = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/dft_fckin_clean_kond_64grid.csv\")\n",
    "dft_data_all =  pd.concat([dft_data1, dft_data2], ignore_index=True)\n",
    "\n",
    "# Feature Daten - bins zu Vext, Vext+chem_res etc\n",
    "expV_data = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/Vext_chem_res_allTEMP_pressure_20b_exp.csv\")\n",
    "#expV_data = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/Vext_allcsv/Vext_allTEMP_64grid_20b.csv\")\n",
    "\n",
    "# Chem_res_bulk explizit - für additional feature \n",
    "chem_res = pd.read_csv(\"/Users/danielbock/MASTERTHESIS/MASTA/DataArchiv/bulk_potentials.csv\")\n",
    "\n",
    "# Kombi aus obigem \n",
    "data = pd.merge(dft_data_all, expV_data, 'inner', on=[\"structure_name\", \"temperature_kelvin\", \"pressure_bar\"])\n",
    "data = pd.merge(data, chem_res, 'inner', on=[\"structure_name\", \"temperature_kelvin\", \"pressure_bar\"])\n",
    "#feature_columns = [col for col in data.columns if is_bin_column(col)]\n",
    "data = data[data.beladung_mol_per_kg > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "feb72edf-11aa-4275-83df-ab1add596f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.1       ,   1.        ,   8.07142857,  15.14285714,\n",
       "        22.21428571,  29.28571429,  36.35714286,  43.42857143,\n",
       "        50.5       ,  57.57142857,  64.64285714,  71.71428571,\n",
       "        78.78571429,  85.85714286,  92.92857143, 100.        ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"pressure_bar\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc7ac1-d80e-4cc3-b276-791fbee4e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures, pressures, combis = tempunddruckunique(data)\n",
    "\n",
    "results_gp = []\n",
    "results_bo = []\n",
    "counter_bad = 0\n",
    "counter_good = 0\n",
    "for T in temperatures:\n",
    "    sub = data[data['temperature_kelvin']==T]\n",
    "    sub = sub.drop_duplicates(subset=['pressure_bar', 'structure_name'], keep='first').reset_index(drop=True)\n",
    "    print(sub.shape)\n",
    "    for p1 in pressures:\n",
    "        for p2 in pressures:\n",
    "            if p1 == p2:\n",
    "                continue\n",
    "            # Hier muss der shit rein\n",
    "            merged, feature_columns = datenfilternundfertigmachenfür(sub, T, T, p1, p2) # funktioniert\n",
    "            if merged.shape==(245, 88):\n",
    "                continue\n",
    "            else:\n",
    "                # hier den ganzen müll rein#\n",
    "                results = GPGPGP(merged, feature_columns)\n",
    "                print(f\"Zustand --> {T}K, {p1}bar und {p2}bar\")\n",
    "                printmirmeinenscheiss(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f084bd75-8286-424e-909e-efcf3736621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²                        : 0.6373\n",
      "Median APE                : 12.34%\n",
      "Mean APE                  : 2994.92%\n",
      "Abs rel dev > 20%         : 34 out of 127\n",
      "Max abs rel dev           : 317099.30%\n"
     ]
    }
   ],
   "source": [
    "T=400\n",
    "p1=1\n",
    "p2=100\n",
    "merged, feature_columns = datenfilternundfertigmachenfür(data, T, T, p1, p2) # funktioniert\n",
    "results = GPGPGP(merged, feature_columns)\n",
    "printmirmeinenscheiss(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ab7ea03-fd57-47e7-8db4-9e6387e1f903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structure_name</th>\n",
       "      <th>pressure_bar</th>\n",
       "      <th>temperature_kelvin</th>\n",
       "      <th>volume_kubAng</th>\n",
       "      <th>grid.dv</th>\n",
       "      <th>density_Atmos_per_kubAng</th>\n",
       "      <th>density_bulk</th>\n",
       "      <th>fraction_of_used_points</th>\n",
       "      <th>beladung_mol_per_kg</th>\n",
       "      <th>beladung_atoms</th>\n",
       "      <th>...</th>\n",
       "      <th>bin_13</th>\n",
       "      <th>bin_14</th>\n",
       "      <th>bin_15</th>\n",
       "      <th>bin_16</th>\n",
       "      <th>bin_17</th>\n",
       "      <th>bin_18</th>\n",
       "      <th>bin_19</th>\n",
       "      <th>x_max_y</th>\n",
       "      <th>x_min_y</th>\n",
       "      <th>chem_potential_bulk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14890</th>\n",
       "      <td>DDR</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>6715.860313</td>\n",
       "      <td>0.025619</td>\n",
       "      <td>855.049395</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.082912</td>\n",
       "      <td>2.940194</td>\n",
       "      <td>21.905488</td>\n",
       "      <td>...</td>\n",
       "      <td>915</td>\n",
       "      <td>838</td>\n",
       "      <td>696</td>\n",
       "      <td>673</td>\n",
       "      <td>619</td>\n",
       "      <td>675</td>\n",
       "      <td>238341</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14891</th>\n",
       "      <td>RRO</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1007.699890</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>565.118379</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.045502</td>\n",
       "      <td>2.008644</td>\n",
       "      <td>2.172355</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>952</td>\n",
       "      <td>920</td>\n",
       "      <td>840</td>\n",
       "      <td>864</td>\n",
       "      <td>700</td>\n",
       "      <td>247720</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14892</th>\n",
       "      <td>MER</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1954.329977</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>727.048515</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.072937</td>\n",
       "      <td>2.819137</td>\n",
       "      <td>5.420276</td>\n",
       "      <td>...</td>\n",
       "      <td>1392</td>\n",
       "      <td>720</td>\n",
       "      <td>1120</td>\n",
       "      <td>1040</td>\n",
       "      <td>832</td>\n",
       "      <td>1040</td>\n",
       "      <td>240032</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14893</th>\n",
       "      <td>EOS</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>682.685342</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>855.860658</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.064011</td>\n",
       "      <td>3.091343</td>\n",
       "      <td>2.228865</td>\n",
       "      <td>...</td>\n",
       "      <td>1076</td>\n",
       "      <td>1056</td>\n",
       "      <td>848</td>\n",
       "      <td>756</td>\n",
       "      <td>772</td>\n",
       "      <td>896</td>\n",
       "      <td>242856</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14894</th>\n",
       "      <td>CFI</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1908.333111</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>508.661083</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.115356</td>\n",
       "      <td>1.925917</td>\n",
       "      <td>3.702907</td>\n",
       "      <td>...</td>\n",
       "      <td>896</td>\n",
       "      <td>864</td>\n",
       "      <td>864</td>\n",
       "      <td>752</td>\n",
       "      <td>624</td>\n",
       "      <td>736</td>\n",
       "      <td>229664</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15012</th>\n",
       "      <td>LIO</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2041.797373</td>\n",
       "      <td>0.007789</td>\n",
       "      <td>975.031449</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.063141</td>\n",
       "      <td>3.410128</td>\n",
       "      <td>7.594363</td>\n",
       "      <td>...</td>\n",
       "      <td>788</td>\n",
       "      <td>700</td>\n",
       "      <td>694</td>\n",
       "      <td>608</td>\n",
       "      <td>576</td>\n",
       "      <td>550</td>\n",
       "      <td>243778</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15013</th>\n",
       "      <td>SVV</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3106.520566</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>521.881574</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.068390</td>\n",
       "      <td>1.838074</td>\n",
       "      <td>6.184524</td>\n",
       "      <td>...</td>\n",
       "      <td>744</td>\n",
       "      <td>784</td>\n",
       "      <td>752</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>496</td>\n",
       "      <td>242440</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15014</th>\n",
       "      <td>PUN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2405.249497</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>872.706332</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.115387</td>\n",
       "      <td>3.701951</td>\n",
       "      <td>8.007341</td>\n",
       "      <td>...</td>\n",
       "      <td>1608</td>\n",
       "      <td>1664</td>\n",
       "      <td>1536</td>\n",
       "      <td>1280</td>\n",
       "      <td>1240</td>\n",
       "      <td>1296</td>\n",
       "      <td>227928</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15015</th>\n",
       "      <td>FER</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2051.260998</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>678.754814</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>2.455479</td>\n",
       "      <td>5.311216</td>\n",
       "      <td>...</td>\n",
       "      <td>960</td>\n",
       "      <td>1056</td>\n",
       "      <td>784</td>\n",
       "      <td>736</td>\n",
       "      <td>800</td>\n",
       "      <td>752</td>\n",
       "      <td>239712</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>JSW</td>\n",
       "      <td>100.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2606.215205</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>520.111221</td>\n",
       "      <td>[0.0018837]</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>1.792958</td>\n",
       "      <td>5.170905</td>\n",
       "      <td>...</td>\n",
       "      <td>680</td>\n",
       "      <td>728</td>\n",
       "      <td>624</td>\n",
       "      <td>520</td>\n",
       "      <td>576</td>\n",
       "      <td>520</td>\n",
       "      <td>247232</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-0.087041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      structure_name  pressure_bar  temperature_kelvin  volume_kubAng  \\\n",
       "14890            DDR         100.0               400.0    6715.860313   \n",
       "14891            RRO         100.0               400.0    1007.699890   \n",
       "14892            MER         100.0               400.0    1954.329977   \n",
       "14893            EOS         100.0               400.0     682.685342   \n",
       "14894            CFI         100.0               400.0    1908.333111   \n",
       "...              ...           ...                 ...            ...   \n",
       "15012            LIO         100.0               400.0    2041.797373   \n",
       "15013            SVV         100.0               400.0    3106.520566   \n",
       "15014            PUN         100.0               400.0    2405.249497   \n",
       "15015            FER         100.0               400.0    2051.260998   \n",
       "15016            JSW         100.0               400.0    2606.215205   \n",
       "\n",
       "        grid.dv  density_Atmos_per_kubAng density_bulk  \\\n",
       "14890  0.025619                855.049395  [0.0018837]   \n",
       "14891  0.003844                565.118379  [0.0018837]   \n",
       "14892  0.007455                727.048515  [0.0018837]   \n",
       "14893  0.002604                855.860658  [0.0018837]   \n",
       "14894  0.007280                508.661083  [0.0018837]   \n",
       "...         ...                       ...          ...   \n",
       "15012  0.007789                975.031449  [0.0018837]   \n",
       "15013  0.011850                521.881574  [0.0018837]   \n",
       "15014  0.009175                872.706332  [0.0018837]   \n",
       "15015  0.007825                678.754814  [0.0018837]   \n",
       "15016  0.009942                520.111221  [0.0018837]   \n",
       "\n",
       "       fraction_of_used_points  beladung_mol_per_kg  beladung_atoms  ...  \\\n",
       "14890                 0.082912             2.940194       21.905488  ...   \n",
       "14891                 0.045502             2.008644        2.172355  ...   \n",
       "14892                 0.072937             2.819137        5.420276  ...   \n",
       "14893                 0.064011             3.091343        2.228865  ...   \n",
       "14894                 0.115356             1.925917        3.702907  ...   \n",
       "...                        ...                  ...             ...  ...   \n",
       "15012                 0.063141             3.410128        7.594363  ...   \n",
       "15013                 0.068390             1.838074        6.184524  ...   \n",
       "15014                 0.115387             3.701951        8.007341  ...   \n",
       "15015                 0.076477             2.455479        5.311216  ...   \n",
       "15016                 0.050415             1.792958        5.170905  ...   \n",
       "\n",
       "      bin_13  bin_14  bin_15  bin_16  bin_17  bin_18  bin_19 x_max_y  x_min_y  \\\n",
       "14890    915     838     696     673     619     675  238341    10.1    -15.0   \n",
       "14891   1000     952     920     840     864     700  247720    10.1    -15.0   \n",
       "14892   1392     720    1120    1040     832    1040  240032    10.1    -15.0   \n",
       "14893   1076    1056     848     756     772     896  242856    10.1    -15.0   \n",
       "14894    896     864     864     752     624     736  229664    10.1    -15.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...      ...   \n",
       "15012    788     700     694     608     576     550  243778    10.1    -15.0   \n",
       "15013    744     784     752     600     600     496  242440    10.1    -15.0   \n",
       "15014   1608    1664    1536    1280    1240    1296  227928    10.1    -15.0   \n",
       "15015    960    1056     784     736     800     752  239712    10.1    -15.0   \n",
       "15016    680     728     624     520     576     520  247232    10.1    -15.0   \n",
       "\n",
       "       chem_potential_bulk  \n",
       "14890            -0.087041  \n",
       "14891            -0.087041  \n",
       "14892            -0.087041  \n",
       "14893            -0.087041  \n",
       "14894            -0.087041  \n",
       "...                    ...  \n",
       "15012            -0.087041  \n",
       "15013            -0.087041  \n",
       "15014            -0.087041  \n",
       "15015            -0.087041  \n",
       "15016            -0.087041  \n",
       "\n",
       "[127 rows x 43 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doto=data[data[\"temperature_kelvin\"]==400]\n",
    "doto=doto[doto[\"pressure_bar\"]==100]\n",
    "doto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f567657d-b301-45fa-a3ec-01bf9e7a8b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec710992-9afb-4bf1-ba3e-ed940d0b4d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
